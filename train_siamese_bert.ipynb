{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from claims_dataset import ClaimEvidenceDataset\n",
        "from siamese_bert import SiameseBert\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim.lr_scheduler as lr_scheduler"
      ],
      "metadata": {
        "id": "i3UjvGquLClU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('data/train.csv')\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state= 42)\n",
        "\n",
        "train_df.to_csv('train_split.csv', index=False)\n",
        "val_df.to_csv('val_split.csv', index=False)"
      ],
      "metadata": {
        "id": "b0QIiZe-NZVb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "\n",
        "class Trainer:\n",
        "    def __init__(self, train_csv, validation_csv, epochs=3):\n",
        "        self.epochs = epochs\n",
        "\n",
        "        self.train_dataset = ClaimEvidenceDataset(train_csv)\n",
        "        self.val_dataset = ClaimEvidenceDataset(validation_csv)\n",
        "        self.train_loader = DataLoader(self.train_dataset, batch_size=32, shuffle=True)\n",
        "        self.val_loader = DataLoader(self.val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "        self.device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "        self.model = SiameseBert().to(self.device)\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=5e-5)\n",
        "        self.scheduler = lr_scheduler.StepLR(self.optimizer, step_size=1, gamma=0.9)\n",
        "\n",
        "        self.best_val_loss = float('inf')\n",
        "\n",
        "    def trainModel(self):\n",
        "        for epoch in range(self.epochs):\n",
        "            # Training Phase\n",
        "            self.model.train()\n",
        "            train_loss = 0\n",
        "            for batch in self.train_loader:\n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "                claim_input_ids = batch['claim_input_ids'].to(self.device)\n",
        "                claim_attention_mask = batch['claim_attention_mask'].to(self.device)\n",
        "                evidence_input_ids = batch['evidence_input_ids'].to(self.device)\n",
        "                evidence_attention_mask = batch['evidence_attention_mask'].to(self.device)\n",
        "                true_labels = batch['labels'].to(self.device)\n",
        "\n",
        "                output = self.model(claim_input_ids, evidence_input_ids, claim_attention_mask, evidence_attention_mask)\n",
        "                loss = self.criterion(output, true_labels)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                train_loss += loss.item()\n",
        "\n",
        "            train_loss /= len(self.train_loader)\n",
        "\n",
        "            # Validation Phase\n",
        "            self.model.eval()\n",
        "            val_loss = 0\n",
        "            correct = 0\n",
        "            total = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for batch in self.val_loader:\n",
        "                    claim_input_ids = batch['claim_input_ids'].to(self.device)\n",
        "                    claim_attention_mask = batch['claim_attention_mask'].to(self.device)\n",
        "                    evidence_input_ids = batch['evidence_input_ids'].to(self.device)\n",
        "                    evidence_attention_mask = batch['evidence_attention_mask'].to(self.device)\n",
        "                    true_labels = batch['labels'].to(self.device)\n",
        "\n",
        "                    output = self.model(claim_input_ids, evidence_input_ids, claim_attention_mask, evidence_attention_mask)\n",
        "                    loss = self.criterion(output, true_labels)\n",
        "                    val_loss += loss.item()\n",
        "\n",
        "                    # Compute accuracy\n",
        "                    predictions = torch.argmax(output, dim=1)\n",
        "                    correct += (predictions == true_labels).sum().item()\n",
        "                    total += true_labels.size(0)\n",
        "\n",
        "            val_loss /= len(self.val_loader)\n",
        "            val_accuracy = correct / total\n",
        "            print(f'Epoch {epoch+1}/{self.epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n",
        "\n",
        "            # Save best model\n",
        "            if val_loss < self.best_val_loss:\n",
        "                self.best_val_loss = val_loss\n",
        "                torch.save(self.model.state_dict(), 'best_model.pth')\n",
        "                print('Saved best model')\n",
        "\n",
        "            self.scheduler.step()\n",
        "            print(f'Updated Learning Rate: {self.scheduler.get_last_lr()[0]:.6f}')\n"
      ],
      "metadata": {
        "id": "K4DpoAjKLZKP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_trainer = Trainer('train_split.csv', 'val_split.csv')\n",
        "model_trainer.trainModel()"
      ],
      "metadata": {
        "id": "6stmAfapRNjI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}